---
# ConfigMap containing the import script
apiVersion: v1
kind: ConfigMap
metadata:
  name: argilla-import-scripts
  namespace: apps
data:
  import_datasets.py: |
    #!/usr/bin/env python3
    """
    Server-side Argilla dataset importer
    Imports OCR datasets from Hugging Face into Argilla for annotation
    """
    import os
    import sys
    import argilla as rg
    from datasets import load_dataset
    from huggingface_hub import HfApi

    # Configuration from environment
    ARGILLA_API_URL = os.environ["ARGILLA_API_URL"]
    ARGILLA_API_KEY = os.environ["ARGILLA_API_KEY"]
    HF_TOKEN = os.environ["HF_TOKEN"]
    DATASET_ID = os.environ.get("HF_DATASET_ID", "goldfish-inc/deepseekocr-output")
    WORKSPACE = os.environ.get("ARGILLA_WORKSPACE", "argilla")
    ARGILLA_DATASET_NAME = os.environ.get("ARGILLA_DATASET_NAME", "deepseekocr-output")

    print(f"üöÄ Argilla Dataset Importer")
    print(f"   API URL: {ARGILLA_API_URL}")
    print(f"   HF Dataset: {DATASET_ID}")
    print(f"   Argilla Dataset: {ARGILLA_DATASET_NAME}")
    print(f"   Workspace: {WORKSPACE}")

    # Verify HF access
    print(f"\nüîç Verifying Hugging Face access...")
    api = HfApi(token=HF_TOKEN)
    user = api.whoami()
    print(f"‚úì Authenticated as: {user['name']}")

    try:
        dataset_info = api.dataset_info(DATASET_ID)
        print(f"‚úì Dataset accessible: {DATASET_ID}")
        print(f"  Private: {dataset_info.private}")
    except Exception as e:
        print(f"‚ùå Cannot access dataset: {e}")
        sys.exit(1)

    # Connect to Argilla
    print(f"\nüîå Connecting to Argilla...")
    client = rg.Argilla(api_url=ARGILLA_API_URL, api_key=ARGILLA_API_KEY)
    print(f"‚úì Connected")

    # Load dataset from HF
    print(f"\nüì• Loading dataset from Hugging Face...")
    try:
        hf_dataset = load_dataset(DATASET_ID, token=HF_TOKEN)
        first_split = list(hf_dataset.keys())[0]
        total_records = len(hf_dataset[first_split])
        print(f"‚úì Dataset loaded: {total_records} records")
    except Exception as e:
        print(f"‚ùå Failed to load dataset: {e}")
        sys.exit(1)

    # Create or get Argilla dataset
    print(f"\nüìã Creating Argilla dataset schema...")

    # Define dataset settings
    settings = rg.Settings(
        fields=[
            rg.TextField(
                name="ocr_text",
                title="OCR Output",
                description="Extracted text from PDF (DeepSeek-OCR)",
                use_markdown=True
            ),
        ],
        questions=[
            rg.TextQuestion(
                name="corrected_text",
                title="Corrected Text",
                description="Review and correct the OCR output if needed",
                required=False
            ),
            rg.LabelQuestion(
                name="quality",
                title="OCR Quality",
                description="Rate the quality of the OCR extraction",
                labels=["excellent", "good", "needs_correction", "poor"],
                required=True
            ),
        ],
        metadata=[
            rg.TermsMetadataProperty(name="pdf_name", title="PDF Name"),
            rg.IntegerMetadataProperty(name="page_number", title="Page Number"),
            rg.TermsMetadataProperty(name="timestamp", title="Processing Time"),
        ],
        guidelines="Review OCR-extracted text from IUU vessel list PDFs. Correct any errors in vessel names, identifiers (IMO, MMSI), or other critical data.",
    )

    # Create dataset
    try:
        argilla_dataset = rg.Dataset(
            name=ARGILLA_DATASET_NAME,
            workspace=WORKSPACE,
            settings=settings,
        )
        argilla_dataset.create()
        print(f"‚úì Dataset '{ARGILLA_DATASET_NAME}' created")
    except Exception as e:
        if "already exists" in str(e).lower():
            print(f"‚ÑπÔ∏è  Dataset '{ARGILLA_DATASET_NAME}' already exists, using existing")
            argilla_dataset = client.datasets(name=ARGILLA_DATASET_NAME, workspace=WORKSPACE)
        else:
            print(f"‚ùå Failed to create dataset: {e}")
            sys.exit(1)

    # Convert HF records to Argilla records
    print(f"\nüì§ Converting and uploading records...")
    argilla_records = []

    for idx, hf_record in enumerate(hf_dataset[first_split]):
        argilla_record = rg.Record(
            fields={
                "ocr_text": hf_record["clean_text"] or hf_record["text"],
            },
            metadata={
                "pdf_name": hf_record["pdf_name"],
                "page_number": hf_record["page_number"],
                "timestamp": hf_record["timestamp"],
            },
        )
        argilla_records.append(argilla_record)

        # Progress indicator
        if (idx + 1) % 50 == 0:
            print(f"  Converted {idx + 1}/{total_records} records...")

    # Upload to Argilla
    print(f"\n‚¨ÜÔ∏è  Uploading {len(argilla_records)} records to Argilla...")
    try:
        argilla_dataset.records.log(argilla_records)
        print(f"‚úÖ Successfully imported {len(argilla_records)} records!")
        print(f"\nüéâ Dataset ready for annotation at:")
        print(f"   {ARGILLA_API_URL}/dataset/{ARGILLA_DATASET_NAME}/annotation-mode")
    except Exception as e:
        print(f"‚ùå Failed to upload records: {e}")
        sys.exit(1)

---
# CronJob for scheduled imports (disabled by default)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: argilla-dataset-importer
  namespace: apps
spec:
  schedule: "0 2 * * *"  # Daily at 2am UTC
  suspend: true  # Start disabled - enable when ready
  jobTemplate:
    metadata:
      labels:
        app: argilla-importer
    spec:
      template:
        metadata:
          labels:
            app: argilla-importer
        spec:
          restartPolicy: OnFailure
          containers:
          - name: importer
            image: python:3.11-slim
            command: ["/bin/bash", "-c"]
            args:
            - |
              set -e
              echo "üì¶ Installing dependencies..."
              pip install --quiet argilla datasets huggingface_hub
              echo "‚úì Dependencies installed"
              echo ""
              python /scripts/import_datasets.py
            env:
            - name: ARGILLA_API_URL
              value: "http://argilla:6900"
            - name: ARGILLA_API_KEY
              valueFrom:
                secretKeyRef:
                  name: argilla-secrets
                  key: ADMIN_API_KEY
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: argilla-secrets
                  key: HF_TOKEN
            - name: HF_DATASET_ID
              value: "goldfish-inc/deepseekocr-output"
            - name: ARGILLA_WORKSPACE
              value: "argilla"
            volumeMounts:
            - name: import-scripts
              mountPath: /scripts
            resources:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                cpu: 500m
                memory: 1Gi
          volumes:
          - name: import-scripts
            configMap:
              name: argilla-import-scripts
              defaultMode: 0755
