{
  "epics": [
    {
      "title": "Epic: Transformers 4.56.x + Exporter Stability",
      "labels": ["area:ml", "priority:p1", "epic", "modernization"],
      "body": "Modernize Python ML stack to Transformers 4.56.x, NumPy 2.x, PyTorch 2.8; robust ONNX export; CI smokes on CPU/GPU; remove Optimum coupling.",
      "issues": [
        {
          "title": "Exporter: adopt dynamic_shapes for dynamo and drop legacy fallback",
          "labels": ["type:feat", "area:ml"],
          "body": "Implement dynamic_shapes path for torch.onnx.export(dynamo=true) and validate on Ubuntu CPU + self-hosted GPU."
        },
        {
          "title": "CI: enable GPU smoke on self-hosted runner",
          "labels": ["type:ops", "area:ci"],
          "body": "Provision GPU runner, set ENABLE_GPU_SMOKE=true; ensure weekly + PR smokes run."
        },
        {
          "title": "Docs: remove Optimum references and update export runbook",
          "labels": ["type:docs", "area:ml"],
          "body": "Sweep docs to use apps/ner-training/export_onnx.py and env.yml only."
        },
        {
          "title": "Guardrails: ONNX size + IO schema check in CI",
          "labels": ["type:feat", "area:ci"],
          "body": "Add limits in train-ner workflow: size threshold and IO name/type checks."
        }
      ]
    },
    {
      "title": "Epic: Label Studio SME Flow (Adapter + Auto-connect)",
      "labels": ["area:product", "priority:p0", "epic", "modernization"],
      "body": "SMEs get real-time NER in Label Studio via ls-triton-adapter; correct model routing and label mapping.",
      "issues": [
        {
          "title": "Adapter: enforce consistent label order and add unit test",
          "labels": ["type:test", "area:ml"],
          "body": "Confirm adapter label list equals trainer labels; CI test fails on mismatch."
        },
        {
          "title": "LS runbook: SME quickstart + troubleshooting",
          "labels": ["type:docs", "area:product"],
          "body": "Add docs/ls-sme-runbook.md covering project setup, predictions, and common errors."
        },
        {
          "title": "Auto-connect: webhook robustness + retries",
          "labels": ["type:feat", "area:infra"],
          "body": "Add retry/backoff and idempotency to auto-connect component; document behavior."
        }
      ]
    },
    {
      "title": "Epic: Triton on Calypso (RTX 4090) Reliability",
      "labels": ["area:infra", "priority:p0", "epic", "modernization"],
      "body": "Keep 4090 focused on inference; ensure model repo deploy, config, monitoring are robust.",
      "issues": [
        {
          "title": "Triton: finalize config.pbtxt for ner-distilbert",
          "labels": ["type:ops", "area:infra"],
          "body": "Review instance_group GPU, dynamic_batching, TensorRT EP; document rationale."
        },
        {
          "title": "Runbook: Calypso Triton deploy + rollback",
          "labels": ["type:docs", "area:infra"],
          "body": "Add docs/runbooks/triton-calypso.md for deploy, restart, rollback, repo structure."
        },
        {
          "title": "Metrics: Triton GPU utilization and error rates",
          "labels": ["type:feat", "area:observability"],
          "body": "Scrape readiness/5xx/GPU util; add alerts and dashboard link."
        }
      ]
    },
    {
      "title": "Epic: Spark GTX Front-of-GPUs Pipeline",
      "labels": ["area:data", "priority:p1", "epic", "modernization"],
      "body": "Stand up Spark on GTX for ETL/aggregation ahead of GPU inference/training; keep 4090 focused on models.",
      "issues": [
        {
          "title": "Bring up Spark node (CPU baseline)",
          "labels": ["type:ops", "area:data"],
          "body": "Provision Spark 3.5.x + Java 17 with S3 access; run local submit JSONL→Parquet."
        },
        {
          "title": "Optional RAPIDS enablement on GTX",
          "labels": ["type:feat", "area:data"],
          "body": "Add RAPIDS plugin and validate SQL speedup; document versions and CUDA."
        },
        {
          "title": "Job: JSONL → Parquet preproc (apps/spark-jobs/ner-preproc)",
          "labels": ["type:feat", "area:data"],
          "body": "Complete scaffold with schema and partitioning; outputs feed trainer."
        },
        {
          "title": "Job: Triton micro-batch inference from Spark",
          "labels": ["type:feat", "area:data"],
          "body": "Implement mapPartitions client batching to Triton; results to Parquet."
        },
        {
          "title": "Security: Spark↔Triton networking and secrets",
          "labels": ["type:sec", "area:data"],
          "body": "Keep Triton private; manage HF/S3 creds via ESC/roles; document."
        }
      ]
    },
    {
      "title": "Epic: CI/CD, Security, and Docs Consolidation",
      "labels": ["area:ci", "priority:p2", "epic", "modernization"],
      "body": "Finalize CI on micromamba envs, unify deps, and update docs/security for the modernized stack.",
      "issues": [
        {
          "title": "Unify Python deps: workflows use env.yml",
          "labels": ["type:ops", "area:ci"],
          "body": "Migrate remaining workflows to apps/ner-training/environment.yml; remove legacy requirements."
        },
        {
          "title": "Docs: Training/export end-to-end guide (2025)",
          "labels": ["type:docs", "area:ml"],
          "body": "Create concise guide covering env, train, export, Triton deploy, LS connect."
        },
        {
          "title": "Security: dependency review + gitleaks sweep",
          "labels": ["type:sec", "area:ci"],
          "body": "Run dependency review with updated pins; ensure secrets via ESC; verify gitleaks."
        }
      ]
    }
  ]
}
