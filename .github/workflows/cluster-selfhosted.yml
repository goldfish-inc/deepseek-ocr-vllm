name: Deploy Cluster (Self-Hosted)

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'cluster/src/**'
      - 'cluster/package.json'
      - 'cluster/tsconfig.json'
      - 'cluster/Pulumi.*.yaml'
      - 'cluster/scripts/**'
      - '.github/workflows/cluster-selfhosted.yml'
      # Use ! to exclude patterns
      - '!cluster/**.md'
      - '!cluster/bin/**'

concurrency:
  group: cluster-selfhosted-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  deploy:
    runs-on: self-hosted
    permissions:
      id-token: write
      contents: read
    env:
      SELF_HOSTED: 'true'
      PULUMI_VERSION: '3.197.0'
      NODE_VERSION: '22.x'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: '10.17.1'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22.x'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build cluster program
        run: pnpm --filter @oceanid/cluster build

      - name: Install ESC CLI
        run: |
          curl -fsSL https://get.pulumi.com/esc/install.sh | sh
          echo "$HOME/.pulumi/bin" >> "$GITHUB_PATH"

      - name: Load kubeconfig from ESC (path or base64, optional)
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
        run: |
          set -euo pipefail
          # 1) If kubeconfigPath is present in ESC, export it directly
          if esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:kubeconfigPath --value string >/dev/null 2>&1; then
            KCPATH=$(esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:kubeconfigPath --value string)
            if [ -n "$KCPATH" ]; then
              echo "KUBECONFIG=$KCPATH" >> "$GITHUB_ENV"
              echo "‚úÖ Using KUBECONFIG path from ESC: $KCPATH"
              exit 0
            fi
          fi

          # 2) Else, if kubeconfigB64 is present, materialize a file and export
          if esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:kubeconfigB64 --show-secrets --value string >/dev/null 2>&1; then
            KCB64=$(esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:kubeconfigB64 --show-secrets --value string)
            if [ -n "$KCB64" ]; then
              echo "$KCB64" | base64 -d > "$RUNNER_TEMP/kubeconfig.yaml"
              echo "KUBECONFIG=$RUNNER_TEMP/kubeconfig.yaml" >> "$GITHUB_ENV"
              echo "‚úÖ Decoded kubeconfig from ESC into $RUNNER_TEMP/kubeconfig.yaml"
              exit 0
            fi
          fi

          echo "‚ÑπÔ∏è  No kubeconfigPath or kubeconfigB64 found in ESC; will use runner environment KUBECONFIG if set."

      - name: Ensure KUBECONFIG is set
        run: |
          set -euo pipefail
          if [ -z "${KUBECONFIG:-}" ]; then
            echo "‚ùå KUBECONFIG is not set. Configure the self-hosted runner to export KUBECONFIG or store kubeconfig in ESC."
            exit 1
          fi
          if [ ! -f "$KUBECONFIG" ]; then
            echo "‚ùå KUBECONFIG path '$KUBECONFIG' does not exist or is not a file."
            exit 1
          fi
          echo "‚úÖ Using kubeconfig at: $KUBECONFIG"

      - name: Pre-flight Checks
        run: |
          chmod +x cluster/scripts/preflight-check.sh
          cluster/scripts/preflight-check.sh

      - name: Validate Container Images
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}
        run: |
          set -euo pipefail
          echo "üîç Validating container images before deployment..."

          # Get CSV worker image from ESC
          CSV_IMAGE=$(esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:csvWorkerImage --value string || echo "")

          if [ -n "$CSV_IMAGE" ]; then
            echo "üì¶ Testing CSV worker image: $CSV_IMAGE"

            # Pull image
            docker pull "$CSV_IMAGE" || {
              echo "‚ùå Failed to pull CSV worker image: $CSV_IMAGE"
              exit 1
            }

            # Run smoke test - container should start
            docker run --rm -d \
              --name csv-worker-test \
              -e DATABASE_URL="postgresql://test:test@localhost:5432/test" \
              -e S3_BUCKET="test-bucket" \
              -e LABEL_STUDIO_URL="http://test" \
              "$CSV_IMAGE" || {
              echo "‚ùå CSV worker container failed to start"
              exit 1
            }

            # Wait for startup (max 15 seconds)
            echo "‚è≥ Waiting for container to initialize..."
            for i in {1..15}; do
              if ! docker ps | grep -q csv-worker-test; then
                echo "‚ùå Container crashed during startup!"
                docker logs csv-worker-test 2>&1 || true
                exit 1
              fi
              sleep 1
            done

            # Check if health endpoint exists (may fail if DB not reachable, that's ok)
            docker exec csv-worker-test wget --spider -q http://localhost:8080/live || {
              echo "‚ö†Ô∏è  Health endpoint not responding (expected without real DB)"
            }

            # Cleanup
            docker stop csv-worker-test || true

            echo "‚úÖ CSV worker image validation passed"
          else
            echo "‚ÑπÔ∏è  No csvWorkerImage in ESC, skipping validation"
          fi

      - name: Authenticate to Pulumi Cloud (OIDC)
        uses: pulumi/auth-actions@v1
        with:
          organization: ryan-taylor
          requested-token-type: urn:pulumi:token-type:access_token:personal
          scope: user:ryan-taylor

      - name: Pulumi Up (cluster)
        uses: pulumi/actions@v5
        with:
          command: up
          stack-name: ryan-taylor/oceanid-cluster/prod
          work-dir: cluster
          refresh: true
          diff: true

      - name: Post-deployment Health Check
        if: always()
        run: |
          chmod +x cluster/scripts/flux-health-check.sh
          # Give controllers time to stabilize after deployment
          echo "Waiting 30 seconds for controllers to stabilize..."
          sleep 30
          cluster/scripts/flux-health-check.sh
