{
  "permissions": {
    "allow": [
      "Bash(pkill:*)",
      "Bash(sshpass:*)",
      "Bash(curl -s -X GET \"https://developers.hostinger.com/api/vps/v1/virtual-machines/712695\" -H \"Authorization: Bearer 3kbA6AzfV703e1EUnjrG3eoMkx6H0qXYrWoA2k8m7c81d76d\")",
      "Bash(curl -s -X GET \"https://developers.hostinger.com/api/vps/v1/virtual-machines/712429\" -H \"Authorization: Bearer FPxCtI4ZMBJwhFcfZk5ZdslHiElluMacxY4kB1N556e3a095\")",
      "Bash(gh issue list:*)",
      "Bash(gh issue view:*)",
      "Bash(export KUBECONFIG=~/.kube/k3s-warp.yaml)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(GIT_SSH_COMMAND=\"ssh -i ~/.ssh/claude-code-gh\" git push origin main)",
      "Bash(gh issue create:*)",
      "Bash(gh issue comment:*)",
      "Bash(gh run list:*)",
      "Read(//Users/rt/.ssh/**)",
      "Bash(pulumi config set:*)",
      "Bash(gh run view:*)",
      "Bash(gh issue close:*)",
      "Bash(kubectl get:*)",
      "Bash(warp-cli status:*)",
      "Bash(warp-cli:*)",
      "Bash(nc:*)",
      "Read(//Users/rt/.kube/**)",
      "Bash(export KUBECONFIG=~/.kube/k3s-tethys-public.yaml)",
      "Bash(timeout 30 kubectl get nodes -o wide)",
      "Read(//private/tmp/**)",
      "Bash(ssh:*)",
      "Bash(curl:*)",
      "Bash(kubectl run:*)",
      "Bash(kubectl logs:*)",
      "Bash(kubectl exec:*)",
      "Bash(timeout 30 kubectl run dnstest-styx --rm -i --image=busybox --restart=Never -- nslookup kubernetes.default)",
      "Bash(timeout 30 kubectl run dnstest-both --rm -i --image=busybox --restart=Never -- nslookup kubernetes.default)",
      "Bash(kubectl:*)",
      "Bash(timeout 30 kubectl run dnstest-fqdn --rm -i --image=busybox --restart=Never -- nslookup kubernetes.default.svc.cluster.local)",
      "Bash(timeout 30 kubectl run final-dns-test --rm -i --image=busybox --restart=Never -- nslookup kubernetes.default.svc.cluster.local)",
      "Bash(timeout 15 kubectl run final-validation --rm -i --image=busybox --restart=Never -- sh -c 'nslookup kubernetes.default.svc.cluster.local && nslookup kube-dns.kube-system.svc.cluster.local')",
      "Bash(gh workflow:*)",
      "Bash(gh run watch:*)",
      "Bash(gh api:*)",
      "Bash(gh run cancel:*)",
      "Read(//tmp/**)",
      "Bash(cat:*)",
      "Bash(awk:*)",
      "Bash(xargs kill:*)",
      "Bash(pulumi config get:*)",
      "Bash(esc env get default/oceanid-cluster pulumiConfig.oceanid-cluster:kubeconfigB64 --value string)",
      "Bash(KUBECONFIG=~/.kube/k3s-tethys-public.yaml kubectl get pods -A)",
      "Bash(KUBECONFIG=~/.kube/k3s-tethys-public.yaml kubectl get namespaces)",
      "Bash(timeout 10 kubectl --kubeconfig=/Users/rt/.kube/k3s-tethys-public.yaml cluster-info)",
      "Bash(export:*)",
      "Bash(pnpm build:*)",
      "Bash(pulumi preview:*)",
      "Bash(pulumi refresh:*)",
      "Bash(pulumi up:*)",
      "Bash(tee:*)",
      "Bash(pulumi state delete:*)",
      "Bash(esc env set:*)",
      "Bash(pulumi config rm:*)",
      "Bash(esc env get:*)",
      "Bash(esc env open:*)",
      "Bash(lsof:*)",
      "Bash(op read:*)",
      "Bash(op:*)",
      "Bash(git rm:*)",
      "Bash(pulumi stack output:*)",
      "Bash(find:*)",
      "Bash(for i in {1..6})",
      "Bash(done)",
      "Bash(git pull:*)",
      "Bash(KUBECONFIG=/Users/rt/.kube/k3s-tethys-public.yaml kubectl describe pod -n apps -l app.kubernetes.io/name=label-studio)",
      "Bash(KUBECONFIG=/Users/rt/.kube/k3s-tethys-public.yaml kubectl get secret label-studio-ls-secrets -n apps -o yaml)",
      "Bash(pulumi stack:*)",
      "Bash(KUBECONFIG=/Users/rt/.kube/k3s-tethys-public.yaml kubectl get deployment csv-ingestion-worker-deployment-16729817 -n apps -o yaml)",
      "Bash(KUBECONFIG=/Users/rt/.kube/k3s-tethys-public.yaml kubectl logs -n apps csv-ingestion-worker-deployment-16729817-6c4df48ddb-gvrps --tail=50)",
      "Read(//Users/rt/**)",
      "Bash(tailscale:*)",
      "Bash(GIT_SSH_COMMAND=\"ssh -i ~/.ssh/claude-code-gh\" git commit -m \"$(cat <<''EOF''\ndocs: update architecture for calypso as K3s cluster member\n\nUpdate network and Kubernetes architecture documentation to reflect calypso GPU workstation joining the cluster as a K3s worker node via Tailscale mesh networking (2025-10-15).\n\nChanges:\n- Node inventory: Add calypso with Tailscale IP 100.83.53.38\n- Network topology: Show 3-node cluster (tethys + calypso active, styx down)\n- Triton Inference Server: Document running as systemd host service on calypso\n- Pod distribution: Update to reflect host-level Tailscale (not DaemonSets)\n- Access patterns: Document Triton HTTP/gRPC access from cluster pods\n\nTechnical details:\n- calypso joined via k3s-agent to tethys at Tailscale IP 100.95.51.125:6443\n- Flannel VXLAN operates over Tailscale mesh for pod networking (10.42.2.0/24)\n- Triton models: distilbert, granite-docling (ports 8000/8001/8002)\n- GPU: NVIDIA RTX 4090 available for pod scheduling\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git restore:*)",
      "Bash(GIT_SSH_COMMAND=\"ssh -i ~/.ssh/claude-code-gh\" git commit -m \"$(cat <<''EOF''\nfeat: implement multi-dataset annotation routing with vertical dimensions\n\nImplement comprehensive annotation data routing infrastructure to support separate HuggingFace datasets for NER and Docling tasks, with vertical-aware organization (maritime, energy, etc.).\n\n**Annotations Sink Enhancements:**\n- Multi-dataset routing based on annotation type (labels â†’ NER, rectanglelabels â†’ Docling)\n- Vertical dimension support via task.data.vertical field\n- Extended outbox schema with target_repo, task_type, vertical columns\n- Multi-repo HF client management for flexible dataset targets\n- Vertical-aware shard paths: vertical={vertical}/schema-{version}/project-{id}/YYYY/MM/DD/HH/batch-{uuid}.jsonl\n\n**Training Infrastructure:**\n- XeT-optimized PDF uploader for Git-based large file handling\n- Normalization script for outbox JSONL â†’ training format conversion\n- Updated NER training workflow to fetch from vertical-aware shards\n- ESC-powered dataset repo configuration (hfDatasetRepoNER, hfDatasetRepoDocling)\n\n**Documentation:**\n- Dataset cards and templates for HuggingFace repos\n- PDF dataset documentation with vertical organization guidelines\n- Architecture updates for go-services and ML backend\n\n**Files Modified:**\n- apps/annotations-sink/main.go (determineTarget routing logic)\n- apps/annotations-sink/outbox.go (multi-repo flush, vertical-aware paths)\n- cluster/src/components/annotationsSink.ts (HF_REPO_NER/DOCLING env vars)\n- .github/workflows/train-ner.yml (shard fetching, normalization)\n\n**New Files:**\n- scripts/hf_xet_pdf_uploader.py (XeT-based PDF ingestion)\n- scripts/normalize_ner_from_outbox.py (training data conversion)\n- docs/datasets/pdfs.md (PDF dataset documentation)\n- docs/dataset-cards/pdfs_README_TEMPLATE.md (HF dataset card template)\n\n**Related Issues:** #118-#126 (ML training work plan)\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(gh pr view:*)"
    ],
    "deny": [],
    "ask": []
  }
}
